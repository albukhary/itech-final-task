name: Deploy | Destroy

on:
  workflow_dispatch:
    inputs:
      # Select Job you want to perform
      action:
        description: 'Action to Perform'
        type: choice
        required: true
        options:
        - Deploy
        - Destroy
env:
  BACKEND_DYNAMO_TABLE_NAME: itech-final-tfstate-lock
  BACKEND_S3_BUCKET_NAME: itech-final-state

jobs:
  ############### If Deploy Option is selected
  create-backend:
    if: ${{ github.event.inputs.action == 'Deploy' }}
    runs-on: ubuntu-latest

    steps:
    - name: Install aws-cli
      run: |
        sudo apt-get update
        sudo apt-get install -y python3-pip
        sudo pip3 install awscli --upgrade
      
    - name: Configure AWS credentials
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      run: |
        aws configure set aws_access_key_id $AWS_ACCESS_KEY_ID
        aws configure set aws_secret_access_key $AWS_SECRET_ACCESS_KEY
        aws configure set default.region us-east-1

    - uses: actions/checkout@v2
      
    - name: Check if DynamoDB table exists
      id: check-dynamodb-table
      run: |
        if aws dynamodb describe-table --table-name ${{ env.BACKEND_DYNAMO_TABLE_NAME }} 2>/dev/null; then
          echo "::set-output name=exists::true"
        else
          echo "::set-output name=exists::false"
        fi
      shell: bash
      
    - name: Create DynamoDB table
      run: |
        aws dynamodb create-table \
          --table-name ${{ env.BACKEND_DYNAMO_TABLE_NAME }} \
          --attribute-definitions AttributeName=LockID,AttributeType=S \
          --key-schema AttributeName=LockID,KeyType=HASH \
          --billing-mode PAY_PER_REQUEST
      if: steps.check-dynamodb-table.outputs.exists == 'false'

    - name: Check if S3 bucket exists
      id: check-s3-bucket
      run: |
        if aws s3api head-bucket --bucket ${{ env.BACKEND_S3_BUCKET_NAME }} 2>/dev/null; then
          echo "::set-output name=exists::true"
        else
          echo "::set-output name=exists::false"
        fi
      shell: bash
      
    - name: Create S3 bucket
      run: |
        aws s3api create-bucket --bucket ${{ env.BACKEND_S3_BUCKET_NAME }} --region us-east-1
      if: steps.check-s3-bucket.outputs.exists == 'false'

    - name: Configure S3 bucket public access block
      run: |
        aws s3api put-public-access-block \
          --bucket ${{ env.BACKEND_S3_BUCKET_NAME }} \
          --public-access-block-configuration \
            "BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true"
  #### Now after backend, deploy network
  tf_plan_apply_vpc:
      name: Deploy VPC to AWS
      needs: [create-backend]
      runs-on: ubuntu-latest
      steps:
      - name: Checkout Repo
        uses: actions/checkout@v2

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v1
        with:
          terraform_version: 1.3.9

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-region: us-east-1
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      - name: Initialize Terraform
        working-directory: ./infrastructure/cloud/vpc
        run: terraform init -input=false          

      - name: Plan Terraform
        id: plan
        working-directory: ./infrastructure/cloud/vpc
        run: |
          terraform plan -input=false -no-color -out=tfplan \
          && terraform show -no-color tfplan          

      - name: Apply Terraform
        if: steps.plan.outcome == 'success'
        id: apply
        working-directory: ./infrastructure/cloud/vpc
        run: |
          terraform apply -auto-approve \
            -input=false \
            -no-color \
            tfplan
  #### Now after backend, deploy EKS
  tf_plan_apply_eks:
    name: Deploy EKS Cluster to AWS
    needs: [tf_plan_apply_vpc]
    runs-on: ubuntu-latest
    steps:
    - name: Checkout Repo
      uses: actions/checkout@v2

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v1
      with:
        terraform_version: 1.3.9

    - name: Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-region: us-east-1
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

    - name: Initialize Terraform
      working-directory: ./infrastructure/cloud/eks
      run: terraform init -input=false          

    - name: Plan Terraform
      id: plan
      working-directory: ./infrastructure/cloud/eks
      run: |
        terraform plan -input=false -no-color -out=tfplan \
        && terraform show -no-color tfplan          
    - name: Apply Terraform
      if: steps.plan.outcome == 'success'
      id: apply
      working-directory: ./infrastructure/cloud/eks
      run: |
        terraform apply -auto-approve \
          -input=false \
          -no-color \
          tfplan
  # After successful deployment of EKS Cluster
  # Deploy app on EKS Cluster
  run_app:
    needs: [tf_plan_apply_eks]
    name: Create K8s resources and run app
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Get kubeconfig file
        run: aws eks update-kubeconfig --name iTech-final-task-cluster --region us-east-1

      - name: Install eksctl
        run: |
          sudo apt-get update && sudo apt-get install -y \
          curl \
          gettext \
          git \
          jq
          sudo curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | sudo tar xz -C /usr/local/bin
          sudo chmod +x /usr/local/bin/eksctl
          dpkg --print-architecture

      - name: Install kubectl
        uses: azure/setup-kubectl@v3

      - name: Install Helm
        uses: azure/setup-helm@v3
        with:
          version: '3.11.2' # default is latest (stable)

      - name: Deploy app to EKS
        working-directory: ./k8s/scripts
        run: |
          sudo chmod +x setup.sh
          /bin/bash setup.sh

  ###-----!!!!!!!!!!----- If you selected to destroy the resources
  ## Destroy app on EKS first
  destroy_app:
    if: ${{ github.event.inputs.action == 'Destroy' }}
    name: Uninstall app & destroy resources on EKS
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Get kubeconfig file
        run: aws eks update-kubeconfig --name iTech-final-task-cluster --region us-east-1

      - name: Install eksctl
        run: |
          sudo apt-get update && sudo apt-get install -y \
          curl \
          gettext \
          git \
          jq
          sudo curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | sudo tar xz -C /usr/local/bin
          sudo chmod +x /usr/local/bin/eksctl
          dpkg --print-architecture

      - name: Install kubectl
        uses: azure/setup-kubectl@v3

      - name: Install Helm
        uses: azure/setup-helm@v3
        with:
          version: '3.11.2' # default is latest (stable)
      - name: Destroy app on EKS
        working-directory: ./k8s/scripts
        run: |
          sudo chmod +x destroy.sh 
          /bin/bash destroy.sh
  # Second destroy EKS cluster
  tf_destroy_eks:
    name: "Destroy EKS cluster"
    needs: [destroy_app]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v2

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v1
        with:
          terraform_version: 1.3.9

      - name: Terraform Init
        id: init
        working-directory: ./infrastructure/cloud/eks
        run: terraform init
        env:
            AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
            AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      
      - name: Terraform Destroy
        id: destroy
        working-directory: ./infrastructure/cloud/eks
        run: terraform destroy -auto-approve #-var-file=variables.tfvars
        env:
            AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
            AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  # Then Destroy Networking - VPC
  tf_destroy_vpc:
    name: "Terraform Destroy VPC - Networking"
    needs: [tf_destroy_eks]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v2

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v1
        with:
          terraform_version: 1.3.9

      - name: Terraform Init
        id: init
        working-directory: ./infrastructure/cloud/vpc
        run: terraform init
        env:
            AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
            AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      
      - name: Terraform Destroy
        id: destroy
        working-directory: ./infrastructure/cloud/vpc
        run: terraform destroy -auto-approve #-var-file=variables.tfvars
        env:
            AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
            AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  #------------------------------
  destroy-backend:
    needs: [tf_destroy_vpc]
    runs-on: ubuntu-latest

    steps:
    - name: Install aws-cli
      run: |
        sudo apt-get update
        sudo apt-get install -y python3-pip
        sudo pip3 install awscli --upgrade
      
    - name: Configure AWS credentials
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      run: |
        aws configure set aws_access_key_id $AWS_ACCESS_KEY_ID
        aws configure set aws_secret_access_key $AWS_SECRET_ACCESS_KEY
        aws configure set default.region us-east-1

    - uses: actions/checkout@v2
      
    - name: Check if DynamoDB table exists
      id: check-dynamodb-table
      run: |
        if aws dynamodb describe-table --table-name ${{ env.BACKEND_DYNAMO_TABLE_NAME }} 2>/dev/null; then
          echo "::set-output name=exists::true"
        else
          echo "::set-output name=exists::false"
        fi
      shell: bash

    - name: Check if S3 bucket exists
      id: check-s3-bucket
      run: |
        if aws s3api head-bucket --bucket ${{ env.BACKEND_S3_BUCKET_NAME }} 2>/dev/null; then
          echo "::set-output name=exists::true"
        else
          echo "::set-output name=exists::false"
        fi
      shell: bash
      
    - name: Delete S3 bucket public access block
      run: |
        aws s3api delete-public-access-block \
        --bucket ${{ env.BACKEND_S3_BUCKET_NAME }}
      if: steps.check-s3-bucket.outputs.exists == 'true' 

    - name: Delete S3 bucket
      run: |
        aws s3 rm s3://${{ env.BACKEND_S3_BUCKET_NAME }} --recursive
        aws s3 rb s3://${{ env.BACKEND_S3_BUCKET_NAME }} --force  
      if: steps.check-s3-bucket.outputs.exists == 'true'

    - name: Delete DynamoDB table
      run: |
        aws dynamodb delete-table \
          --table-name ${{ env.BACKEND_DYNAMO_TABLE_NAME }} \
      if: steps.check-dynamodb-table.outputs.exists == 'true'