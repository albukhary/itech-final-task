name: Build | Push | Deploy | Destroy

on:
  # push:
  #   branches:
  #     - main
  workflow_dispatch:
    inputs:
      # Select Job you want to perform
      action:
        description: 'Action to Perform'
        type: choice
        required: true
        options:
        - Deploy
        - Destroy
        - Build-Push-Image
        - Deploy-App-to-EKS
        - Test_Deploy_App
        - Test_Destroy_App
env:
  BACKEND_DYNAMO_TABLE_NAME: itech-final-tfstate-lock
  BACKEND_S3_BUCKET_NAME: itech-final-state

jobs:
  ############### If Deploy Option is selected
  create-backend:
    if: ${{ github.event.inputs.action == 'Deploy' }}
    runs-on: ubuntu-latest

    steps:
    - name: Install aws-cli
      run: |
        sudo apt-get update
        sudo apt-get install -y python3-pip
        sudo pip3 install awscli --upgrade
      
    - name: Configure AWS credentials
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      run: |
        aws configure set aws_access_key_id $AWS_ACCESS_KEY_ID
        aws configure set aws_secret_access_key $AWS_SECRET_ACCESS_KEY
        aws configure set default.region us-east-1

    - uses: actions/checkout@v2
      
    - name: Check if DynamoDB table exists
      id: check-dynamodb-table
      run: |
        if aws dynamodb describe-table --table-name ${{ env.BACKEND_DYNAMO_TABLE_NAME }} 2>/dev/null; then
          echo "::set-output name=exists::true"
        else
          echo "::set-output name=exists::false"
        fi
      shell: bash
      
    - name: Create DynamoDB table
      run: |
        aws dynamodb create-table \
          --table-name ${{ env.BACKEND_DYNAMO_TABLE_NAME }} \
          --attribute-definitions AttributeName=LockID,AttributeType=S \
          --key-schema AttributeName=LockID,KeyType=HASH \
          --billing-mode PAY_PER_REQUEST
      if: steps.check-dynamodb-table.outputs.exists == 'false'

    - name: Check if S3 bucket exists
      id: check-s3-bucket
      run: |
        if aws s3api head-bucket --bucket ${{ env.BACKEND_S3_BUCKET_NAME }} 2>/dev/null; then
          echo "::set-output name=exists::true"
        else
          echo "::set-output name=exists::false"
        fi
      shell: bash
      
    - name: Create S3 bucket
      run: |
        aws s3api create-bucket --bucket ${{ env.BACKEND_S3_BUCKET_NAME }} --region us-east-1
      if: steps.check-s3-bucket.outputs.exists == 'false'

    - name: Configure S3 bucket public access block
      run: |
        aws s3api put-public-access-block \
          --bucket ${{ env.BACKEND_S3_BUCKET_NAME }} \
          --public-access-block-configuration \
            "BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true"
  #### Now after backend, deploy network
  tf_plan_apply_vpc:
      name: Deploy VPC to AWS
      needs: [create-backend]
      runs-on: ubuntu-latest
      steps:
      - name: Checkout Repo
        uses: actions/checkout@v2

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v1
        with:
          terraform_version: 1.3.9

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-region: us-east-1
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      - name: Initialize Terraform
        working-directory: ./infrastructure/cloud/vpc
        run: terraform init -input=false          

      - name: Plan Terraform
        id: plan
        working-directory: ./infrastructure/cloud/vpc
        run: |
          terraform plan -input=false -no-color -out=tfplan \
          && terraform show -no-color tfplan          

      - name: Apply Terraform
        if: steps.plan.outcome == 'success'
        id: apply
        working-directory: ./infrastructure/cloud/vpc
        run: |
          terraform apply -auto-approve \
            -input=false \
            -no-color \
            tfplan
  #### Now after backend, deploy EKS
  tf_plan_apply_eks:
    name: Deploy EKS Cluster to AWS
    needs: [tf_plan_apply_vpc]
    runs-on: ubuntu-latest
    steps:
    - name: Checkout Repo
      uses: actions/checkout@v2

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v1
      with:
        terraform_version: 1.3.9

    - name: Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-region: us-east-1
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

    - name: Initialize Terraform
      working-directory: ./infrastructure/cloud/eks
      run: terraform init -input=false          

    - name: Plan Terraform
      id: plan
      working-directory: ./infrastructure/cloud/eks
      run: |
        terraform plan -input=false -no-color -out=tfplan \
        && terraform show -no-color tfplan          
#        -var "instance_type=${{ github.event.inputs.instance_type }}" \
#        -var "instance_num=${{ github.event.inputs.instance_num }}" \
    - name: Apply Terraform
      if: steps.plan.outcome == 'success'
      id: apply
      working-directory: ./infrastructure/cloud/eks
      run: |
        terraform apply -auto-approve \
          -input=false \
          -no-color \
          tfplan
  # After successful deployment of EKS Cluster
  run_app:
    name: Create K8s resources and run app
    needs: [tf_plan_apply_eks]
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Get kubeconfig file
        run: aws eks update-kubeconfig --name iTech-final-task-cluster --region us-east-1

      - name: Install eksctl
        uses: weaveworks/eksctl-action@v0.3.0

      # - name: Install kubectl
      #   uses: azure/setup-kubectl@v1
      - name: Install kubectl
        uses: dawidd6/action-install-kubectl@v1
        with:
          kubectl-version: '1.26.1'

      - name: Install Helm
        uses: helm/setup-helm@v1
        with:
          helm-version: '3.11.2'

      - name: Deploy app to EKS
        working-directory: ./k8s/scripts
        run: |
          sudo chmod +x setup.sh
          /bin/bash setup.sh
  ###-----!!!!!!!!!!----- If you selected to destroy the resources
  destroy_app:
    name: Uninstall app & destroy K8s resources
    if: ${{ github.event.inputs.action == 'Destroy' }}
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Get kubeconfig file
        run: aws eks update-kubeconfig --name iTech-final-task-cluster --region us-east-1

      - name: Install eksctl
        uses: weaveworks/eksctl-action@v0.3.0

      # - name: Install kubectl
      #   uses: azure/setup-kubectl@v1
      - name: Install kubectl
        uses: dawidd6/action-install-kubectl@v1
        with:
          kubectl-version: '1.26.1'

      - name: Install Helm
        uses: helm/setup-helm@v1
        with:
          helm-version: '3.11.2'

      - name: Destroy app on EKS
        working-directory: ./k8s/scripts
        run: |
          sudo chmod +x destroy.sh 
          /bin/bash destroy.sh
  # Second destroy EKS cluster
  tf_destroy_eks:
    name: "Destroy EKS cluster"
    # if: ${{ github.event.inputs.action == 'Destroy' }}
    needs: [destroy_app]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v2

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v1
        with:
          terraform_version: 1.3.9

      - name: Terraform Init
        id: init
        working-directory: ./infrastructure/cloud/eks
        run: terraform init
        env:
            AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
            AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      
      - name: Terraform Destroy
        id: destroy
        working-directory: ./infrastructure/cloud/eks
        run: terraform destroy -auto-approve #-var-file=variables.tfvars
        env:
            AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
            AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  # Then Destroy Networking - VPC
  tf_destroy_vpc:
    name: "Terraform Destroy VPC - Networking"
    needs: [tf_destroy_eks]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v2

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v1
        with:
          terraform_version: 1.3.9

      - name: Terraform Init
        id: init
        working-directory: ./infrastructure/cloud/vpc
        run: terraform init
        env:
            AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
            AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      
      - name: Terraform Destroy
        id: destroy
        working-directory: ./infrastructure/cloud/vpc
        run: terraform destroy -auto-approve #-var-file=variables.tfvars
        env:
            AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
            AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  #------------------------------
  destroy-backend:
    if: ${{ github.event.inputs.action == 'Destroy' }}
    needs: [tf_destroy_vpc]
    runs-on: ubuntu-latest

    steps:
    - name: Install aws-cli
      run: |
        sudo apt-get update
        sudo apt-get install -y python3-pip
        sudo pip3 install awscli --upgrade
      
    - name: Configure AWS credentials
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      run: |
        aws configure set aws_access_key_id $AWS_ACCESS_KEY_ID
        aws configure set aws_secret_access_key $AWS_SECRET_ACCESS_KEY
        aws configure set default.region us-east-1

    - uses: actions/checkout@v2
      
    - name: Check if DynamoDB table exists
      id: check-dynamodb-table
      run: |
        if aws dynamodb describe-table --table-name ${{ env.BACKEND_DYNAMO_TABLE_NAME }} 2>/dev/null; then
          echo "::set-output name=exists::true"
        else
          echo "::set-output name=exists::false"
        fi
      shell: bash

    - name: Check if S3 bucket exists
      id: check-s3-bucket
      run: |
        if aws s3api head-bucket --bucket ${{ env.BACKEND_S3_BUCKET_NAME }} 2>/dev/null; then
          echo "::set-output name=exists::true"
        else
          echo "::set-output name=exists::false"
        fi
      shell: bash
      
    - name: Delete S3 bucket public access block
      run: |
        aws s3api delete-public-access-block \
        --bucket ${{ env.BACKEND_S3_BUCKET_NAME }}
      if: steps.check-s3-bucket.outputs.exists == 'true' 

    - name: Delete S3 bucket
      run: |
        aws s3 rm s3://${{ env.BACKEND_S3_BUCKET_NAME }} --recursive
        aws s3 rb s3://${{ env.BACKEND_S3_BUCKET_NAME }} --force  
      if: steps.check-s3-bucket.outputs.exists == 'true'

    - name: Delete DynamoDB table
      run: |
        aws dynamodb delete-table \
          --table-name ${{ env.BACKEND_DYNAMO_TABLE_NAME }} \
      if: steps.check-dynamodb-table.outputs.exists == 'true'

##### Job to build and push app image to docker hub
  build-and-push:
    if: ${{ github.event.inputs.action == 'Build-Push-Image' }}
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Login to Docker Hub
        uses: docker/login-action@v1
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Build and Push Docker Image
        uses: docker/build-push-action@v2
        with:
          context: ./application
          push: true
          tags: ${{ secrets.DOCKER_USERNAME }}/my-app:${{ github.sha }}

####### Here is a job to deploy our application to EKS
  deploy-to-eks:
    if: ${{ github.event.inputs.action == 'Deploy-App-to-EKS' }}
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Authenticate to EKS cluster
        id: authenticate_eks
        run: aws eks update-kubeconfig --name iTechFinalTask-cluster

      - name: Apply Deployment
#        if: steps.plan.authenticate_eks == 'success'
        id: deploy_app
        run: |
          kubectl apply -f k8s/deployment.yaml
      - name: Apply Ingress
#        if: steps.plan.deploy_app == 'success'
        run: |
          kubectl apply -f k8s/ingress.yaml




  # After successful deployment of EKS Cluster
  run_app_test:
    if: ${{ github.event.inputs.action == 'Test_Deploy_App' }}
    name: TEST Create K8s resources and run app
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Get kubeconfig file
        run: aws eks update-kubeconfig --name iTech-final-task-cluster --region us-east-1

      - name: Install eksctl
        run: |
          sudo apt-get update && sudo apt-get install -y \
          curl \
          gettext \
          git \
          jq
          sudo curl --silent --location -o /usr/local/bin/eksctl "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz"
          sudo chmod +x /usr/local/bin/eksctl

      - name: Install kubectl
        uses: azure/setup-kubectl@v3

      - name: Install Helm
        uses: azure/setup-helm@v3
        with:
          version: '3.11.2' # default is latest (stable)

      - name: Deploy app to EKS
        working-directory: ./k8s/scripts
        run: |
          sudo chmod +x setup.sh
          /bin/bash setup.sh




  destroy_app_test:
    if: ${{ github.event.inputs.action == 'Test_Destroy_App' }}
    name: TEST Uninstall app & destroy K8s resources
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Get kubeconfig file
        run: aws eks update-kubeconfig --name iTech-final-task-cluster --region us-east-1

      - name: Install eksctl
        uses: moia-oss/setup-eksctl@v1

      - name: Install kubectl
        uses: azure/setup-kubectl@v3

      - name: Install Helm
        uses: azure/setup-helm@v3
        with:
          version: '3.11.2' # default is latest (stable)

      - name: Destroy app on EKS
        working-directory: ./k8s/scripts
        run: |
          sudo chmod +x destroy.sh 
          /bin/bash destroy.sh